{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1be0ecc",
   "metadata": {},
   "source": [
    "# СТЕГОАНАЛИЗ ИЗОБРАЖЕНИЙ С ПОМОЩЬЮ ГЛУБОКОГО МАШИННОГО ОБУЧЕНИЯ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a759b",
   "metadata": {},
   "source": [
    "## Аннотация\n",
    "Рассматривается современное состояние проблемы стегоанализа цифровых изображений, направленной на исследование и разработку эффективных методов выявления стеганографически скрытых (визуально незаметных) сообщений в контейнерах- изображениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ce9c3",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "\n",
    "1. [Импорт необходимых библиотек](#first)\n",
    "2. [Получение и предобработка данных](#second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df71c7",
   "metadata": {},
   "source": [
    "## 1. Импорт необходимых библиотек\n",
    "<span id=\"first\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf110cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from stegano import exifHeader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b80a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5645b9",
   "metadata": {},
   "source": [
    "## 2. Получение и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14367cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures_names = os.listdir('data/')\n",
    "\n",
    "pictures_clear = pictures_names[:round(len(pictures_names) * 0.65)]\n",
    "pictures_clear_df = pd.DataFrame({\n",
    "    \"picture_link\": pictures_clear,\n",
    "    \"is_clear\": np.ones(len(pictures_clear), dtype=int)\n",
    "})\n",
    "\n",
    "pictures_graphed = pictures_names[round(len(pictures_names) * 0.65):]\n",
    "pictures_graphed_df = pd.DataFrame({\n",
    "    \"picture_link\": pictures_graphed,\n",
    "    \"is_clear\": np.zeros(len(pictures_graphed), dtype=int)\n",
    "})\n",
    "\n",
    "data = shuffle(pd.concat([pictures_clear_df, pictures_graphed_df]))\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.picture_link = data.picture_link.apply(lambda val: \"data/\" + val)\n",
    "data = data[data.picture_link != \"data/.DS_Store\"]\n",
    "\n",
    "def image_resizing(link):\n",
    "    img = Image.open(link)\n",
    "    img = img.resize((64,64))\n",
    "    img.save(link)\n",
    "    return link\n",
    "\n",
    "data.picture_link.apply(image_resizing)\n",
    "\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce342df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.is_clear)\n",
    "plt.xlabel(\"Класс объекта\")\n",
    "plt.ylabel(\"Кол-во объектов данного класса\")\n",
    "plt.title(\"Гистограмма отношения классов\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19986e",
   "metadata": {},
   "source": [
    "## 3. Стенография"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(row):\n",
    "    try:\n",
    "        image_link = row[\"picture_link\"]\n",
    "        is_clear = row[\"is_clear\"]\n",
    "\n",
    "        image = Image.open(image_link)\n",
    "        image.load()\n",
    "\n",
    "        im = Image.new('RGB', image.size, (255, 255, 255))\n",
    "        im.paste(image, None)\n",
    "        im.save(image_link)\n",
    "\n",
    "\n",
    "        secret_text = \"\"\n",
    "        new_link = \"data_prepared/\" + image_link.split(\"/\")[1].split(\".\")[0] + image_link.split(\"/\")[1].split(\".\")[1] + \".jpg\"\n",
    "        \n",
    "        if not bool(is_clear):\n",
    "            secret_text = ''.join(random.choice(string.ascii_letters) for i in range(200))\n",
    "            secret = exifHeader.hide(image_link, new_link, secret_message=secret_text)\n",
    "        \n",
    "        else:\n",
    "            image.save(new_link)\n",
    "\n",
    "        row[\"picture_link\"] = new_link \n",
    "        row[\"secret\"] = secret_text\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"secret\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc111fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in tqdm(range(0, data.shape[0], 5)):\n",
    "    data[index:index + 5] = data[index:index + 5].apply(preprocess_images, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a935ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a39944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exifHeader.reveal(\"data_prepared/dog2424.jpg\"), Image.open(\"data_prepared/dog2424.jpg\").size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data_marked.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba107f",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa02265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"Описантельный класс датасета для удобной работы с ним\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file=None, transform=None):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                csv_file (string): Путь к csv файлу с разметкой\n",
    "                transform (callable, optional): Опционально, трансформации применяемые к картинкам\n",
    "        \"\"\"\n",
    "        \n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.annotations.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_info = self.annotations.iloc[idx]\n",
    "        image = io.imread(img_info[0])\n",
    "        label = img_info[1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if len(image.shape) == 2 or image.shape[0] == 1: # если черно-белая\n",
    "            image = image.repeat( 3, 1, 1)\n",
    "            \n",
    "        sample = image, label\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((64, 64)), transforms.ToTensor()])\n",
    "train_dataset = Dataset(csv_file='data_marked.csv', transform=transform)\n",
    "\n",
    "part = np.arange(0, int(len(train_dataset) * 0.8))\n",
    "val_part = np.arange(int(len(train_dataset) * 0.8), len(train_dataset))\n",
    "\n",
    "sampler_to_train = torch.utils.data.SubsetRandomSampler(part)\n",
    "sampler_to_val = torch.utils.data.SubsetRandomSampler(val_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6442e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler_to_train) \n",
    "validate_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler_to_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67794b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_loader:\n",
    "    print(image.shape, label)\n",
    "    plt.imshow(image[0].transpose(0, -1).transpose(1, 0))\n",
    "    plt.title(label[0])\n",
    "    plt.show();\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e81211",
   "metadata": {},
   "source": [
    "## Нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(inp: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Считает гауссову функцию для каждого входного тензора\n",
    "    Args:\n",
    "            inp (torch.Tensor): входной тензор\n",
    "    Returns:\n",
    "            torch.Tensor: тензор после применения Гаусса\n",
    "    \"\"\"\n",
    "    \n",
    "    return torch.exp(-((inp - torch.mean(inp)) ** 2) / (torch.std(inp)) ** 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173613f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessing(nn.Module):\n",
    "    \"\"\"Считает светку с помощью использования пространственного фильтра высоких частот с фиксированным ядром\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.kv_filter = (\n",
    "            torch.tensor([\n",
    "                [\n",
    "                    [-1.0, 2.0, -2.0, 2.0, -1.0],\n",
    "                    [2.0, -6.0, 8.0, -6.0, 2.0],\n",
    "                    [-2.0, 8.0, -12.0, 8.0, -2.0],\n",
    "                    [2.0, -6.0, 8.0, -6.0, 2.0],\n",
    "                    [-1.0, 2.0, -2.0, 2.0, -1.0],\n",
    "                ],\n",
    "                [\n",
    "                    [-1.0, 2.0, -2.0, 2.0, -1.0],\n",
    "                    [2.0, -6.0, 8.0, -6.0, 2.0],\n",
    "                    [-2.0, 8.0, -12.0, 8.0, -2.0],\n",
    "                    [2.0, -6.0, 8.0, -6.0, 2.0],\n",
    "                    [-1.0, 2.0, -2.0, 2.0, -1.0],\n",
    "                ],\n",
    "                [\n",
    "                    [-1.0, 2.0, -2.0, 2.0, -1.0],\n",
    "                    [2.0, -6.0, 8.0, -6.0, 2.0],\n",
    "                    [-2.0, 8.0, -12.0, 8.0, -2.0],\n",
    "                    [2.0, -6.0, 8.0, -6.0, 2.0],\n",
    "                    [-1.0, 2.0, -2.0, 2.0, -1.0],\n",
    "                ],\n",
    "            ]\n",
    "            ).view(1, 3, 5, 5))\n",
    "\n",
    "    def forward(self, inp: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Возвращает тензор, над которым была произведена свертка\"\"\"\n",
    "\n",
    "        return F.conv2d(inp, self.kv_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f505c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPool(nn.Module):\n",
    "    \"\"\"\n",
    "        Данный класс возвращает экземпляр свертки, выстроенной по необходимым параметрам, \n",
    "        то есть  схема данного блока это conv -> batch norm -> gaussian -> average pooling\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int = 16,\n",
    "            out_channels: int = 32,\n",
    "            conv_kernel_size: tuple[int, int] = (3, 3),\n",
    "            conv_stride: int = 1,\n",
    "            pool_stride: int = 2,\n",
    "            pool_kernel_size: tuple[int, int] = (3, 3),\n",
    "            pool_padding: int = 0,\n",
    "            activation_function = None\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=conv_kernel_size,\n",
    "            stride=conv_stride,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.pool = nn.AvgPool2d(kernel_size=pool_kernel_size, stride=pool_stride, padding=pool_padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "    def forward(self, inp: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Соответсвенно conv->batch norm->activation->average pooling.\"\"\"\n",
    "        if self.activation_function is None:\n",
    "            return self.pool(gaussian(self.bn(self.conv(inp))))\n",
    "        \n",
    "        return self.pool(self.activation_function(self.bn(self.conv(inp))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Реализация сверточной нейронной сети\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.layer1 = ConvPool(in_channels=1, out_channels=16,  conv_kernel_size=(5, 5), pool_kernel_size=(3,3))\n",
    "        self.layer2 = ConvPool(in_channels=16, out_channels=64, conv_kernel_size=(3, 3), activation_function=nn.ReLU())\n",
    "        self.layer3 = ConvPool(in_channels=64, out_channels=128, conv_kernel_size=(3, 3), activation_function=nn.ReLU())\n",
    "        \n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(in_features=100352, out_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=128, out_features=2),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Вернет логиты для данного изображения\"\"\"\n",
    "        with torch.no_grad():\n",
    "            out = ImageProcessing()(image)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fully_connected(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dde89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN()\n",
    "inp_image = torch.randn((1, 3, 256, 256))\n",
    "net(inp_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2215e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
