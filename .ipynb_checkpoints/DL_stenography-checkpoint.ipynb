{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1be0ecc",
   "metadata": {},
   "source": [
    "# СТЕГОАНАЛИЗ ИЗОБРАЖЕНИЙ С ПОМОЩЬЮ ГЛУБОКОГО МАШИННОГО ОБУЧЕНИЯ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a759b",
   "metadata": {},
   "source": [
    "## Аннотация\n",
    "Рассматривается современное состояние проблемы стегоанализа цифровых изображений, направленной на исследование и разработку эффективных методов выявления стеганографически скрытых (визуально незаметных) сообщений в контейнерах- изображениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ce9c3",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "\n",
    "1. [Импорт необходимых библиотек](#first)\n",
    "2. [Получение и предобработка данных](#second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df71c7",
   "metadata": {},
   "source": [
    "## 1. Импорт необходимых библиотек\n",
    "<span id=\"first\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf110cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.signal import convolve2d\n",
    "from skimage import io, transform\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b80a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = (3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5645b9",
   "metadata": {},
   "source": [
    "## 2. Получение и предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1037ff4",
   "metadata": {},
   "source": [
    "### 2.1 Алгоримт  WOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3cb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "def WOW(cover, payload, params):\n",
    "    # Input:  cover ... image\n",
    "    #         payload ..... payload in bits per pixel\n",
    "    # Output: stego ....... resulting image with embedded payload\n",
    "\n",
    "    ## Get 2D wavelet filters - Daubechies 8\n",
    "    # 1D high pass decomposition filter\n",
    "    hpdf = np.matrix([[-0.0544158422, 0.3128715909, -0.6756307363, 0.5853546837, 0.0158291053, -0.2840155430, \n",
    "                    -0.0004724846, 0.1287474266, 0.0173693010, -0.0440882539, -0.0139810279, 0.0087460940,\n",
    "                    0.0048703530, -0.0003917404, -0.0006754494, -0.0001174768]])\n",
    "    # 1D low pass decomposition filter\n",
    "    lpdf = np.matrix((-1) ** np.array(range(hpdf.shape[1])) * np.fliplr(hpdf).A)\n",
    "    # construction of 2D wavelet filters\n",
    "    F = []\n",
    "    F.append(lpdf.T * hpdf)\n",
    "    F.append(hpdf.T * lpdf)\n",
    "    F.append(hpdf.T * hpdf)\n",
    "\n",
    "    ## Get embedding costs\n",
    "    # inicialization\n",
    "    cover = cover.astype('float64')\n",
    "    p = params\n",
    "    wetCost = 10 ** 10\n",
    "    sizeCover = cover.shape\n",
    "\n",
    "    # add padding \n",
    "    padSize = np.max(np.concatenate([F[0].shape, F[1].shape, F[2].shape]))\n",
    "    coverPadded = np.pad(cover, ((padSize, padSize), (padSize, padSize)), 'symmetric')\n",
    "\n",
    "    # compute directional residual and suitability xi for each filter\n",
    "    xi = []\n",
    "    for fIndex in range(0, 3):\n",
    "        # compute residual\n",
    "        R = convolve2d(coverPadded, F[fIndex], 'same')\n",
    "\n",
    "        # compute suitability\n",
    "        xi.append(convolve2d(abs(R), np.rot90(abs(F[fIndex]), 2), 'same'))\n",
    "        # correct the suitability shift if filter size is even\n",
    "        if np.mod(np.size(F[fIndex], 0), 2) == 0:\n",
    "            xi[fIndex] = np.roll(xi[fIndex], 1, axis=0)\n",
    "            # xi[fIndex] = circshift(xi[fIndex], [1, 0])\n",
    "        if np.mod(np.size(F[fIndex], 1), 2) == 0:\n",
    "            xi[fIndex] = np.roll(xi[fIndex], 1, axis=1)\n",
    "            # xi[fIndex] = circshift(xi[fIndex], [0, 1])\n",
    "        \n",
    "        # remove padding\n",
    "        a_idx_s = int((np.size(xi[fIndex], 0) - sizeCover[0]) / 2)\n",
    "        a_idx_e = int(np.size(xi[fIndex], 0) - (np.size(xi[fIndex], 0) - sizeCover[0]) / 2)\n",
    "        b_idx_s = int((np.size(xi[fIndex], 1) - sizeCover[1]) / 2)\n",
    "        b_idx_e = int(np.size(xi[fIndex], 1) - (np.size(xi[fIndex], 1) - sizeCover[1]) / 2)\n",
    "        xi[fIndex] = xi[fIndex][a_idx_s:a_idx_e, b_idx_s:b_idx_e]\n",
    "    \n",
    "    # compute embedding costs \\rho\n",
    "    rho = (xi[0] ** p + xi[1] ** p + xi[2] ** p) ** (-1 / p)\n",
    "\n",
    "    # adjust embedding costs\n",
    "    rho[rho > wetCost] = wetCost    # threshold on the costs\n",
    "    rho[np.isnan(rho)] = wetCost    # if all xi{} are zero threshold the cost\n",
    "    rhoP1 = rho.copy()\n",
    "    rhoM1 = rho.copy()\n",
    "    rhoP1[cover == 255] = wetCost   # do not embed +1 if the pixel has max value\n",
    "    rhoM1[cover == 0] = wetCost     # do not embed -1 if the pixel has min value\n",
    "\n",
    "    # Embedding simulator\n",
    "    stego = EmbeddingSimulator(cover, rhoP1, rhoM1, payload * cover.size, False)\n",
    "    distortion_local = rho[cover != stego]\n",
    "    distortion = np.sum(distortion_local)\n",
    "\n",
    "    return stego, distortion\n",
    "\n",
    "\n",
    "def EmbeddingSimulator(x, rhoP1, rhoM1, m, fixEmbeddingChanges):\n",
    "    n = x.size\n",
    "    m_lambda = calc_lambda(rhoP1, rhoM1, m, n)\n",
    "    pChangeP1 = (np.exp(-m_lambda * rhoP1)) / (1 + np.exp(-m_lambda * rhoP1) + np.exp(-m_lambda * rhoM1))\n",
    "    pChangeM1 = (np.exp(-m_lambda * rhoM1)) / (1 + np.exp(-m_lambda * rhoP1) + np.exp(-m_lambda * rhoM1))\n",
    "    if fixEmbeddingChanges:\n",
    "        np.random.seed(100)\n",
    "    else:\n",
    "        np.random.seed(int(time.time()))\n",
    "    \n",
    "    randChange = np.random.rand(*x.shape)\n",
    "    y = x.copy()\n",
    "    y[randChange < pChangeP1] = y[randChange < pChangeP1] + 1\n",
    "    y[np.logical_and(randChange >= pChangeP1, randChange < (pChangeP1+pChangeM1))] = y[np.logical_and(randChange >= pChangeP1, randChange < (pChangeP1+pChangeM1))] - 1\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def calc_lambda(rhoP1, rhoM1, message_length, n):\n",
    "    l3 = 1e+3\n",
    "    m3 = float(message_length + 1)\n",
    "    iterations = 0\n",
    "    while m3 > message_length:\n",
    "        l3 = l3 * 2\n",
    "        pP1 = np.exp(-l3 * rhoP1) / (1 + np.exp(-l3 * rhoP1) + np.exp(-l3 * rhoM1))\n",
    "        pM1 = np.exp(-l3 * rhoM1) / (1 + np.exp(-l3 * rhoP1) + np.exp(-l3 * rhoM1))\n",
    "        m3 = ternary_entropyf(pP1, pM1)\n",
    "        iterations = iterations + 1\n",
    "        if iterations > 10:\n",
    "            m_lambda = l3\n",
    "            return\n",
    "    \n",
    "    l1 = 0\n",
    "    m1 = float(n)\n",
    "    m_lambda = 0\n",
    "\n",
    "    alpha = float(message_length) / n\n",
    "    # limit search to 30 iterations\n",
    "    # and require that relative payload embedded is roughly within 1/1000 of the required relative payload\n",
    "    while float(m1-m3)/n > (alpha/1000.0) and (iterations < 30):\n",
    "        m_lambda = l1 + (l3 - l1) / 2\n",
    "        pP1 = (np.exp(-l3 * rhoP1)) / (1 + np.exp(-l3 * rhoP1) + np.exp(-l3 * rhoM1))\n",
    "        pM1 = (np.exp(-l3 * rhoM1)) / (1 + np.exp(-l3 * rhoP1) + np.exp(-l3 * rhoM1))\n",
    "        m2 = ternary_entropyf(pP1, pM1)\n",
    "        if m2 < message_length:\n",
    "            l3 = m_lambda\n",
    "            m3 = m2\n",
    "        else:\n",
    "            l1 = m_lambda\n",
    "            m1 = m2\n",
    "        iterations = iterations + 1\n",
    "\n",
    "    return m_lambda\n",
    "\n",
    "\n",
    "def ternary_entropyf(pP1, pM1):\n",
    "    eps = 3e-16\n",
    "    p0 = 1 - pP1 - pM1\n",
    "    P = np.concatenate([p0.flatten(order='F'), pP1.flatten(order='F'), pM1.flatten(order='F')])\n",
    "    P[P == 0] = 1e-16       # clear warning: divide by zero encountered in log2\n",
    "    H = - (P * np.log2(P))\n",
    "    H[np.logical_or(P < eps, P > (1 - eps))] = 0\n",
    "    Ht = sum(H)\n",
    "    return Ht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f763541",
   "metadata": {},
   "source": [
    "### 2.2 Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef439b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data_path = \"data/clear_data\"\n",
    "stego_data_path = \"data/stego_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14367cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures_names = os.listdir('data/clear_data')\n",
    "\n",
    "for name in tqdm(pictures_names):\n",
    "    if not name.startswith('.'):\n",
    "        payload = 0.4               \n",
    "        params = -1              \n",
    "        \n",
    "        filename = os.path.join(clear_data_path, name)\n",
    "        cover = Image.open(filename)\n",
    "        cover = cover.resize((256,256))\n",
    "        \n",
    "        cover = cover.convert('L')\n",
    "        cover.save(filename)\n",
    "\n",
    "#         cover = np.array(cover)\n",
    "        \n",
    "#         stego, distortion = WOW(cover, payload, params)\n",
    "#         Image.fromarray(np.uint8(stego)).save(os.path.join(stego_data_path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_paths = list(map(lambda x: os.path.join(clear_data_path, x), os.listdir(clear_data_path)))\n",
    "pictures_clear_df = pd.DataFrame({\n",
    "    \"picture_link\": clear_paths,\n",
    "    \"is_changed\": np.zeros(len(clear_paths), dtype=int)\n",
    "})\n",
    "\n",
    "stego_paths = list(map(lambda x: os.path.join(stego_data_path, x), os.listdir(stego_data_path)))\n",
    "pictures_graphed_df = pd.DataFrame({\n",
    "    \"picture_link\": stego_paths,\n",
    "    \"is_changed\": np.ones(len(stego_paths), dtype=int)\n",
    "})\n",
    "\n",
    "data = shuffle(pd.concat([pictures_clear_df, pictures_graphed_df]))\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(index=data[data[\"is_changed\"] == 1].sample(n=2300)['is_changed'].index, inplace=True)\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce342df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(data.is_changed)\n",
    "plt.xlabel(\"Класс объекта\")\n",
    "plt.ylabel(\"Кол-во объектов данного класса\")\n",
    "plt.title(\"Гистограмма отношения классов\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['picture_link'] != \"data/clear_data/.DS_Store\"]\n",
    "data = data[data['picture_link'] != \"data/stego_data/.DS_Store\"]\n",
    "data.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba107f",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa02265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"Описантельный класс датасета для удобной работы с ним\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file=None, transform=None):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                csv_file (string): Путь к csv файлу с разметкой\n",
    "                transform (callable, optional): Опционально, трансформации применяемые к картинкам\n",
    "        \"\"\"\n",
    "        \n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.annotations.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_info = self.annotations.iloc[idx]\n",
    "        image = io.imread(img_info[0])\n",
    "        label = img_info[1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "                \n",
    "        sample = torch.tensor([image], dtype=torch.float32), label\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "train_dataset = Dataset(csv_file='data.csv')\n",
    "\n",
    "train_part = np.arange(0, int(len(train_dataset) * 0.7))\n",
    "val_part = np.arange(int(len(train_dataset) * 0.2), len(train_dataset))\n",
    "test_part = np.arange(int(len(train_dataset) * 0.9), len(train_dataset))\n",
    "\n",
    "sampler_to_train = torch.utils.data.SubsetRandomSampler(train_part)\n",
    "sampler_to_val = torch.utils.data.SubsetRandomSampler(val_part)\n",
    "sampler_to_test = torch.utils.data.SubsetRandomSampler(test_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6442e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, sampler=sampler_to_train) \n",
    "val_loader = DataLoader(train_dataset, batch_size=128, sampler=sampler_to_val)\n",
    "test_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67794b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_loader:\n",
    "    print(torch.tensor(image).shape, label.sum())\n",
    "    plt.imshow(image[0].transpose(0, -1).transpose(1, 0))\n",
    "    plt.title(label[0])\n",
    "    plt.show();\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e81211",
   "metadata": {},
   "source": [
    "## Нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(inp: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Считает гауссову функцию для каждого входного тензора\n",
    "    Args:\n",
    "            inp (torch.Tensor): входной тензор\n",
    "    Returns:\n",
    "            torch.Tensor: тензор после применения Гаусса\n",
    "    \"\"\"\n",
    "    \n",
    "    return torch.exp(-((inp - torch.mean(inp)) ** 2) / (torch.std(inp)) ** 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173613f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessing(nn.Module):\n",
    "    \"\"\"Считает свёртку с помощью использования пространственного фильтра высоких частот с фиксированным ядром\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.kv_filter = (\n",
    "            torch.tensor(\n",
    "                [\n",
    "                    [-1.0, 2.0, -2.0, 2.0, -1.0],\n",
    "                    [2.0, -6.0, 8.0, -6.0, 2.0],\n",
    "                    [-2.0, 8.0, -12.0, 8.0, -2.0],\n",
    "                    [2.0, -6.0, 8.0, -6.0, 2.0],\n",
    "                    [-1.0, 2.0, -2.0, 2.0, -1.0],\n",
    "                ],\n",
    "                \n",
    "            ).view(1, 1, 5, 5) / 12.0\n",
    "        )\n",
    "\n",
    "    def forward(self, inp: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Возвращает тензор, над которым была произведена свертка\"\"\"\n",
    "        return F.conv2d(inp, self.kv_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f505c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPool(nn.Module):\n",
    "    \"\"\"\n",
    "        Данный класс возвращает экземпляр свертки, выстроенной по необходимым параметрам, \n",
    "        то есть  схема данного блока это conv -> batch norm -> gaussian -> average pooling\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int = 16,\n",
    "            out_channels: int = 32,\n",
    "            conv_kernel_size: tuple[int, int] = (3, 3),\n",
    "            conv_stride: int = 1,\n",
    "            pool_stride: int = 2,\n",
    "            pool_kernel_size: tuple[int, int] = (3, 3),\n",
    "            pool_padding: int = 0,\n",
    "        ) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=conv_kernel_size,\n",
    "            stride=conv_stride,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.pool = nn.AvgPool2d(kernel_size=pool_kernel_size, stride=pool_stride, padding=pool_padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, inp: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Соответсвенно conv->batch norm->activation->average pooling.\"\"\"\n",
    "        \n",
    "        return self.pool(gaussian(self.bn(self.conv(inp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Реализация сверточной нейронной сети\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1 = ConvPool(\n",
    "            in_channels=1,\n",
    "            out_channels=16,\n",
    "            conv_kernel_size=(5, 5),\n",
    "            pool_kernel_size=(3,3)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = ConvPool(\n",
    "            in_channels=16,\n",
    "            out_channels=64,\n",
    "            conv_kernel_size=(3, 3),\n",
    "        )\n",
    "        \n",
    "        self.layer3 = ConvPool(\n",
    "            in_channels=64,\n",
    "            out_channels=128,\n",
    "            conv_kernel_size=(3, 3),\n",
    "        )\n",
    "        \n",
    "        self.fully_connected = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(in_features=100352, out_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=128, out_features=2),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Вернет логиты для данного изображения\"\"\"\n",
    "        with torch.no_grad():\n",
    "            out = ImageProcessing()(image)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fully_connected(out)\n",
    "        return out                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, train_loader, val_loader, test_loader, model, lr=0.02, epoch=20):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.epoch = epoch\n",
    "        self.optimizer = torch.optim.Adamax(\n",
    "            self.model.parameters(),\n",
    "            lr=lr,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8,\n",
    "            weight_decay=0,\n",
    "        )\n",
    "        self.loss_fn = nn.NLLLoss()\n",
    "        \n",
    "    def validation(self):\n",
    "        accuracy_list = []\n",
    "        \n",
    "        for xb, yb in self.val_loader:\n",
    "            y_pred = self.model(xb).data.max(1)[1]\n",
    "            accuracy = accuracy_score(y_pred, yb)\n",
    "            accuracy_list.append(accuracy)\n",
    "                \n",
    "        return np.mean(np.array(accuracy_list))\n",
    "        \n",
    "    def test(self):\n",
    "        accuracy_list = []\n",
    "        \n",
    "        for xb, yb in self.test_loader:\n",
    "            y_pred = self.model(xb).data.max(1)[1]\n",
    "            accuracy = accuracy_score(y_pred, yb)\n",
    "            accuracy_list.append(accuracy)\n",
    "                \n",
    "        return np.mean(np.array(accuracy_list))\n",
    "        \n",
    "    def fit(self):\n",
    "        losses = []\n",
    "        valid_accuracies = []\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "        \n",
    "        for i in range(1, self.epoch + 1):\n",
    "            epoch_train_accuracies = []\n",
    "            counter = 1\n",
    "            self.model.train()\n",
    "            for X, y in tqdm(self.train_loader):\n",
    "                print(f'Iteration {counter} started')\n",
    "                counter += 1\n",
    "                clear_output(wait=True)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                y_pred = self.model(X)\n",
    "                \n",
    "                loss = self.loss_fn(y_pred, y)\n",
    "                losses.append(loss.item())  \n",
    "                print(loss.item())\n",
    "                \n",
    "                y_pred = y_pred.data.max(1)[1]\n",
    "                accuracy = accuracy_score(y_pred, y)\n",
    "                epoch_train_accuracies.append(accuracy)\n",
    "                \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "            print(\"Starting validation\")\n",
    "            \n",
    "            self.model.eval()\n",
    "            valid_accuracy = self.validation()\n",
    "            train_accuracy = np.mean(np.array(epoch_train_accuracies))\n",
    "            \n",
    "            valid_accuracies.append(valid_accuracy)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            \n",
    "            print(\"Valid_accuracy in:\", valid_accuracy)\n",
    "            print(\"Train_accuracy in:\", train_accuracy)\n",
    "            print(f'Epoch {i} is finished!')\n",
    "            time.sleep(10)\n",
    "            \n",
    "        test_accuracy = self.test()  \n",
    "        \n",
    "        print(f\"Mean loss is: {np.mean(np.array(losses))}\")\n",
    "        print(f\"Mean valid_accuracy is: {np.mean(np.array(valid_accuracies))}\")\n",
    "        print(f\"Mean train_accuracy is: {np.mean(np.array(train_accuracies))}\")\n",
    "        \n",
    "        return losses, valid_accuracies, train_accuracies, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dde89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2215e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses, valid_accuracies, train_accuracies, test_accuracy = Evaluation(train_loader=train_loader, val_loader=val_loader, test_loader=test_loader, model=net).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976ce91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
